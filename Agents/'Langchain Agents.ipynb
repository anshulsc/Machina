{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Agents (LangChain version)\n",
        "\n",
        "Three Main components:\n",
        "\n",
        "\n",
        "*   LLM\n",
        "*   Tool\n",
        "*   Agents themselves\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vZSN9umN8XCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain"
      ],
      "metadata": {
        "id": "juF-pkVmBa1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o50RQ_uFkfZv",
        "outputId": "6939a847-e5e2-4337-bf3f-b118fb187fc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m851.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain openai tiktoken cohere"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import OpenAI"
      ],
      "metadata": {
        "id": "W_XxCf-n8bKc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(\n",
        "    openai_api_key=\"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\",\n",
        "    temperature=0,\n",
        "    model_name=\"text-davinci-003\"\n",
        " )"
      ],
      "metadata": {
        "id": "bxDIpLkwB29_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize Tool"
      ],
      "metadata": {
        "id": "i-zL5sMeCM6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMMathChain\n",
        "from langchain.agents import Tool\n",
        "\n",
        "llm_math = LLMMathChain(llm = llm)\n",
        "\n",
        "# intialize the math tool\n",
        "math_tool = Tool(\n",
        "    name = 'Calculator',\n",
        "    func = llm_math.run,\n",
        "    description = 'Useful for when you need to answer questions about math'\n",
        ")\n",
        "tools = [math_tool]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WL3y9S3CPt8",
        "outputId": "3a5bc4c4-4d0e-4031-804d-cd278eaa3087"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm_math/base.py:56: UserWarning: Directly instantiating an LLMMathChain with an llm is deprecated. Please instantiate with llm_chain argument or using the from_llm class method.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize Agent\n"
      ],
      "metadata": {
        "id": "F-7I5YlYDGLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent\n",
        "\n",
        "zero_shot_agent = initialize_agent(\n",
        "      agent = \"zero-shot-react-description\",\n",
        "      tools=tools,\n",
        "      llm = llm,\n",
        "      verbose=True,\n",
        "      max_iterations=3\n",
        ")"
      ],
      "metadata": {
        "id": "c2MtIahQDFHO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zero_shot_agent(\"What is 2+287*7?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x34ROLQwD3Pc",
        "outputId": "fb585402-d554-4351-9d71-f4c5849100fd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to calculate this equation\n",
            "Action: Calculator\n",
            "Action Input: 2+287*7\u001b[0m\n",
            "Observation: Calculator is not a valid tool, try one of [Calulator].\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to use a calculator\n",
            "Action: Calulator\n",
            "Action Input: 2+287*7\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mAnswer: 2011\u001b[0m\n",
            "Thought:"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-9Qvrmgf4mTfjdG3hsylu25hT on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-9Qvrmgf4mTfjdG3hsylu25hT on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: 2011\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'What is 2+287*7?', 'output': '2011'}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "2+287*7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2ChwCT8EkxW",
        "outputId": "037b5e84-faef-4729-ff1e-41d35c91eae3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2011"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zero_shot_agent(\"What is capital of India?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkjVZcAnFn-Y",
        "outputId": "17504d82-f37e-487e-d06d-dca41c040ea3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to find out what the capital of India is.\n",
            "Action: Research\n",
            "Action Input: India capital\u001b[0m\n",
            "Observation: Research is not a valid tool, try one of [Calulator].\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to find out what the capital of India is using a calculator.\n",
            "Action: Calculator\n",
            "Action Input: India capital\u001b[0m\n",
            "Observation: Calculator is not a valid tool, try one of [Calulator].\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to find out what the capital of India is using a calculator.\n",
            "Action: Calculator\n",
            "Action Input: India\u001b[0m\n",
            "Observation: Calculator is not a valid tool, try one of [Calulator].\n",
            "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'What is capital of India?',\n",
              " 'output': 'Agent stopped due to iteration limit or time limit.'}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding simple LLM CHain so that it can answer basic things"
      ],
      "metadata": {
        "id": "GpkFSiBJGeoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables = [\"query\"],\n",
        "    template = \"{query}\"\n",
        ")\n",
        "\n",
        "llm_chain = LLMChain(llm=llm, prompt = prompt)\n",
        "\n",
        "llm_tool = Tool(\n",
        "    name = 'Language Model',\n",
        "    func = llm_chain.run,\n",
        "    description = 'use this tool for general purpose queries and logic'\n",
        ")\n"
      ],
      "metadata": {
        "id": "OwFIxPgCGRIi"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools.append(llm_tool)"
      ],
      "metadata": {
        "id": "WcZAnkdNHmnO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zero_shot_agent = initialize_agent(\n",
        "      agent = \"zero-shot-react-description\",\n",
        "      tools=tools,\n",
        "      llm = llm,\n",
        "      verbose=True,\n",
        "      max_iterations=3\n",
        ")"
      ],
      "metadata": {
        "id": "yZtepXq9Hqnm"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zero_shot_agent(\"What is capital of India?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dh9iKPtlHttQ",
        "outputId": "231cc602-0ee4-473d-df23-e0c2663df1d6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to find the name of the capital of India.\n",
            "Action: Language Model\n",
            "Action Input: \"What is the capital of India?\"\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3m\n",
            "\n",
            "The capital of India is New Delhi.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: The capital of India is New Delhi.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'What is capital of India?',\n",
              " 'output': 'The capital of India is New Delhi.'}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prebuilt tools\n",
        "from langchain.agents import load_tools\n",
        "\n",
        "tools = load_tools(\n",
        "    ['llm-math'],\n",
        "    llm = llm\n",
        ")"
      ],
      "metadata": {
        "id": "aS-T_ol9Hvv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RljQWy9aITfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agents + Internet"
      ],
      "metadata": {
        "id": "Kg1GmenSIYfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain openai google-search-results wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bu-YT9DuIZ7x",
        "outputId": "87536c32-6b3a-49a2-861d-dc07e2515376"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent:\n",
        "Agents use an LLM to determine which actons to take and in what order. An action can either be using a tool and observing its output, or returning to the user."
      ],
      "metadata": {
        "id": "We-zPC7RJJLS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a Database"
      ],
      "metadata": {
        "id": "Ebt_e2VFJlwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import MetaData\n",
        "\n",
        "metadata_obj = MetaData()"
      ],
      "metadata": {
        "id": "sne57W8WIoBz"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import Column, Integer, String, Table, Date, Float\n",
        "\n",
        "stocks = Table(\n",
        "    \"stocks\",\n",
        "    metadata_obj,\n",
        "    Column(\"obs_id\", Integer, primary_key=True),\n",
        "    Column('stock_ticker', String(4), nullable=False),\n",
        "    Column(\"price\", Float, nullable=False),\n",
        "    Column(\"date\", Date, nullable=False)\n",
        ")"
      ],
      "metadata": {
        "id": "VeMFBffNJ4Z_"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import create_engine, insert\n",
        "\n",
        "engine = create_engine(\"sqlite:///:memory:\")\n",
        "metadata_obj.create_all(engine)"
      ],
      "metadata": {
        "id": "QDJ5YmmAO2Rf"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "observations = [\n",
        "    [1, 'ABC', 200, datetime(2023, 1, 1)],\n",
        "    [2, 'ABC', 208, datetime(2023, 1, 2)],\n",
        "    [3, 'ABC', 232, datetime(2023, 1, 3)],\n",
        "    [4, 'ABC', 225, datetime(2023, 1, 4)],\n",
        "    [5, 'ABC', 226, datetime(2023, 1, 5)],\n",
        "    [6, 'XYZ', 810, datetime(2023, 1, 1)],\n",
        "    [7, 'XYZ', 803, datetime(2023, 1, 2)],\n",
        "    [8, 'XYZ', 798, datetime(2023, 1, 3)],\n",
        "    [9, 'XYZ', 795, datetime(2023, 1, 4)],\n",
        "    [10, 'XYZ', 791, datetime(2023, 1, 5)],\n",
        "]\n",
        ""
      ],
      "metadata": {
        "id": "6Py3iuAIQeqP"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_obs(obs):\n",
        "  stmt = insert(stocks).values(\n",
        "      obs_id = obs[0],\n",
        "      stock_ticker=obs[1],\n",
        "      price = obs[2],\n",
        "      date = obs[3]\n",
        "  )\n",
        "  with engine.begin() as conn:\n",
        "    conn.execute(stmt)"
      ],
      "metadata": {
        "id": "bQJmY-SaQr3X"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for obs in observations:\n",
        "  insert_obs(obs)"
      ],
      "metadata": {
        "id": "4yWgDMn4SIwn"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_experimental -qU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xTf7IUsUgPr",
        "outputId": "52dbb244-9d3f-4bdd-a8bd-e3ef35561803"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/151.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/151.6 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.6/151.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.sql_database import SQLDatabase\n",
        "from langchain_experimental.sql import SQLDatabaseChain\n",
        "\n",
        "db = SQLDatabase(engine)\n",
        "sql_chain = SQLDatabaseChain(llm=llm, database=db, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REoxdYudSMmj",
        "outputId": "67ed0df6-3113-4f7a-ad38-eb81830bb7db"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_experimental/sql/base.py:75: UserWarning: Directly instantiating an SQLDatabaseChain with an llm is deprecated. Please instantiate with llm_chain argument or using the from_llm class method.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import Tool\n",
        "\n",
        "sql_tool = Tool(\n",
        "    name = 'Stock DB',\n",
        "    func = sql_chain.run,\n",
        "    description = \"Useful for when you need to answer questions about stocks and their prices\"\n",
        ")"
      ],
      "metadata": {
        "id": "wpcVQFw7TAKe"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Agent Types\n",
        "Langchain pre-built agents involves involves three variables:\n",
        "*  defining the tools\n",
        "*  LLM\n",
        "*  defining the agent type\n",
        "\n",
        "### Agent Type : Zero Shot react"
      ],
      "metadata": {
        "id": "r_7Mos9dWJA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent\n",
        "\n",
        "tools = load_tools(\n",
        "    ['llm-math'],\n",
        "    llm = llm\n",
        ")\n",
        "tools.append(sql_tool)\n",
        "\n",
        "zero_shot_agent = initialize_agent(\n",
        "    agent = 'zero-shot-react-description',\n",
        "    tools = tools,\n",
        "    llm = llm,\n",
        "    verbose=True,\n",
        "    max_iterations=3\n",
        ")"
      ],
      "metadata": {
        "id": "pelSpBOTWIuY"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zero_shot_agent(\"What is the multiplication of the ratio between stock \" +\n",
        "    \"prices for 'ABC' and 'XYZ' in January 3rd and the ratio \" +\n",
        "    \"between the same stock prices in January the 4th?\"\n",
        ")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmRmgA46TevO",
        "outputId": "c9e70eff-fa26-4f79-99f4-fab08ce024e6"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to compare the stock prices of 'ABC' and 'XYZ' on two different days\n",
            "Action: Stock DB\n",
            "Action Input: Stock prices of 'ABC' and 'XYZ' on January 3rd and January 4th\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
            "Stock prices of 'ABC' and 'XYZ' on January 3rd and January 4th\n",
            "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT stock_ticker, price, date FROM stocks WHERE (stock_ticker = 'ABC' OR stock_ticker = 'XYZ') AND (date = '2023-01-03' OR date = '2023-01-04')\u001b[0m\n",
            "SQLResult: \u001b[33;1m\u001b[1;3m[('ABC', 232.0, '2023-01-03'), ('ABC', 225.0, '2023-01-04'), ('XYZ', 798.0, '2023-01-03'), ('XYZ', 795.0, '2023-01-04')]\u001b[0m\n",
            "Answer:"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-9Qvrmgf4mTfjdG3hsylu25hT on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mOn January 3rd, ABC was 232.0 and XYZ was 798.0. On January 4th, ABC was 225.0 and XYZ was 795.0.\u001b[0m\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Observation: \u001b[33;1m\u001b[1;3mOn January 3rd, ABC was 232.0 and XYZ was 798.0. On January 4th, ABC was 225.0 and XYZ was 795.0.\u001b[0m\n",
            "Thought:"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-9Qvrmgf4mTfjdG3hsylu25hT on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-9Qvrmgf4mTfjdG3hsylu25hT on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m I need to calculate the ratio between the two stock prices on each day\n",
            "Action: Calculator\n",
            "Action Input: 232.0/798.0 and 225.0/795.0\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-9Qvrmgf4mTfjdG3hsylu25hT on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-9Qvrmgf4mTfjdG3hsylu25hT on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-9Qvrmgf4mTfjdG3hsylu25hT on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Observation: \u001b[36;1m\u001b[1;3mAnswer: 0.08228117463469994\u001b[0m\n",
            "Thought:"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-9Qvrmgf4mTfjdG3hsylu25hT on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-9Qvrmgf4mTfjdG3hsylu25hT on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-9Qvrmgf4mTfjdG3hsylu25hT on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-9Qvrmgf4mTfjdG3hsylu25hT on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m I need to calculate the multiplication of the two ratios\n",
            "Action: Calculator\n",
            "Action Input: 0.08228117463469994 * 0.08228117463469994\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-9Qvrmgf4mTfjdG3hsylu25hT on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-9Qvrmgf4mTfjdG3hsylu25hT on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-9Qvrmgf4mTfjdG3hsylu25hT on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Observation: \u001b[36;1m\u001b[1;3mAnswer: 0.00677019169926599\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': \"What is the multiplication of the ratio between stock prices for 'ABC' and 'XYZ' in January 3rd and the ratio between the same stock prices in January the 4th?\",\n",
              " 'output': 'Agent stopped due to iteration limit or time limit.'}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(zero_shot_agent.agent.llm_chain.prompt.template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COqUuIZ0X61i",
        "outputId": "4fa1e371-70d9-47fc-dc4b-eca2e076b5dd"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer the following questions as best you can. You have access to the following tools:\n",
            "\n",
            "Calculator: Useful for when you need to answer questions about math.\n",
            "Stock DB: Useful for when you need to answer questions about stocks and their prices\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [Calculator, Stock DB]\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "\n",
            "Question: {input}\n",
            "Thought:{agent_scratchpad}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agent Type : Conversational React\n",
        "\n",
        "Zero Shot but with Memory"
      ],
      "metadata": {
        "id": "cVhWM_0re1YP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tools = load_tools(\n",
        "    ['llm-math'],\n",
        "    llm = llm\n",
        ")\n",
        "\n",
        "tools.append(sql_tool)"
      ],
      "metadata": {
        "id": "9tO250U1Z7JA"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key = \"chat_history\")\n",
        "\n",
        "conversational_agent = initialize_agent(\n",
        "    agent = 'conversational-react-description',\n",
        "    tools = tools,\n",
        "    llm = llm,\n",
        "    verbose = True,\n",
        "    max_iterations=3,\n",
        "    memory = memory\n",
        ")"
      ],
      "metadata": {
        "id": "5jYTgxR2fMUi"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversational_agent(\"Please provide me the stock prices for ABC on January the 1st \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAVozz8WgI6B",
        "outputId": "e8a3243f-025d-4b24-f652-1e5339beca58"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Thought: Do I need to use a tool? Yes\n",
            "Action: Stock DB\n",
            "Action Input: ABC on January the 1st\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
            "ABC on January the 1st\n",
            "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT price FROM stocks WHERE stock_ticker = 'ABC' AND date = '2023-01-01'\u001b[0m\n",
            "SQLResult: \u001b[33;1m\u001b[1;3m[(200.0,)]\u001b[0m\n",
            "Answer:"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-9Qvrmgf4mTfjdG3hsylu25hT on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mThe price of ABC on January the 1st was 200.0.\u001b[0m\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Observation: \u001b[33;1m\u001b[1;3mThe price of ABC on January the 1st was 200.0.\u001b[0m\n",
            "Thought:"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-9Qvrmgf4mTfjdG3hsylu25hT on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-9Qvrmgf4mTfjdG3hsylu25hT on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-9Qvrmgf4mTfjdG3hsylu25hT on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
            "AI: Is there anything else I can help you with?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Please provide me the stock prices for ABC on January the 1st ',\n",
              " 'chat_history': '',\n",
              " 'output': 'Is there anything else I can help you with?'}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversational_agent(\"Cn you tell me its ratio of stock prices with XYZ on same day \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y93mkJzPgZb2",
        "outputId": "ece2d571-a839-4e88-8180-a29ff831763b"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: Stock DB\n",
            "Action Input: ABC and XYZ stock prices on January 1st\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
            "ABC and XYZ stock prices on January 1st\n",
            "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT stock_ticker, price FROM stocks WHERE date = '2023-01-01'\u001b[0m\n",
            "SQLResult: \u001b[33;1m\u001b[1;3m[('ABC', 200.0), ('XYZ', 810.0)]\u001b[0m\n",
            "Answer:"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-9Qvrmgf4mTfjdG3hsylu25hT on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mABC stock price on January 1st was 200.0 and XYZ stock price on January 1st was 810.0.\u001b[0m\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Observation: \u001b[33;1m\u001b[1;3mABC stock price on January 1st was 200.0 and XYZ stock price on January 1st was 810.0.\u001b[0m\n",
            "Thought:"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-9Qvrmgf4mTfjdG3hsylu25hT on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-9Qvrmgf4mTfjdG3hsylu25hT on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-9Qvrmgf4mTfjdG3hsylu25hT on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
            "AI: The ratio of ABC to XYZ stock prices on January 1st was 0.24691358. Is there anything else I can help you with?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Cn you tell me its ratio of stock prices with XYZ on same day ',\n",
              " 'chat_history': 'Human: Please provide me the stock prices for ABC on January the 1st \\nAI: Is there anything else I can help you with?',\n",
              " 'output': 'The ratio of ABC to XYZ stock prices on January 1st was 0.24691358. Is there anything else I can help you with?'}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(conversational_agent.agent.llm_chain.prompt.template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5bt5eZNgyrt",
        "outputId": "16fa6a4f-08bc-450b-8332-3740faab27cf"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assistant is a large language model trained by OpenAI.\n",
            "\n",
            "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
            "\n",
            "TOOLS:\n",
            "------\n",
            "\n",
            "Assistant has access to the following tools:\n",
            "\n",
            "> Calculator: Useful for when you need to answer questions about math.\n",
            "> Stock DB: Useful for when you need to answer questions about stocks and their prices\n",
            "\n",
            "To use a tool, please use the following format:\n",
            "\n",
            "```\n",
            "Thought: Do I need to use a tool? Yes\n",
            "Action: the action to take, should be one of [Calculator, Stock DB]\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "```\n",
            "\n",
            "When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n",
            "\n",
            "```\n",
            "Thought: Do I need to use a tool? No\n",
            "AI: [your response here]\n",
            "```\n",
            "\n",
            "Begin!\n",
            "\n",
            "Previous conversation history:\n",
            "{chat_history}\n",
            "\n",
            "New input: {input}\n",
            "{agent_scratchpad}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent : REACT DOCSTORE"
      ],
      "metadata": {
        "id": "HDa7BwIbhqRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import Wikipedia\n",
        "from langchain.agents.react.base import DocstoreExplorer\n",
        "\n",
        "docstore  = DocstoreExplorer(Wikipedia())\n",
        "\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Search\",\n",
        "        func = docstore.search,\n",
        "        description='search wikipedia'\n",
        "    ),\n",
        "    Tool(\n",
        "        name = \"Lookup\",\n",
        "        func = docstore.lookup,\n",
        "        description = 'look up a term in wikipedia'\n",
        "    )\n",
        "]"
      ],
      "metadata": {
        "id": "nGK8gF9yhPrr"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "docstore_agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent = 'react-docstore',\n",
        "    verbose=True,\n",
        "    max_iterations=3,\n",
        ")"
      ],
      "metadata": {
        "id": "Vz5-BRwWinet"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docstore_agent(\"What is CWC 2023?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojJSYinAi91_",
        "outputId": "243720e8-c112-4093-e5bf-35aa65598409"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to search CWC 2023 and find what it is.\n",
            "Action: Search[CWC 2023]\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mCould not find [CWC 2023]. Similar: ['2023 Cricket World Cup', '2015 Cricket World Cup', '2023 Cricket World Cup qualification', 'International cricket in 2023', 'M. Chinnaswamy Stadium', '2011 Cricket World Cup', '2023 Cricket World Cup Qualifier', '2019 Cricket World Cup', '2023 Cricket World Cup Qualifier Play-off', '2023 in sports']\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m CWC 2023 could be referring to the 2023 Cricket World Cup.\n",
            "Action: Search[2023 Cricket World Cup]\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mCould not find [2023 Cricket World Cup]. Similar: ['2023 Cricket World Cup', '2023 Cricket World Cup Qualifier', 'Cricket World Cup', '2023 Cricket World Cup squads', '2023 Cricket World Cup statistics', '2023 Cricket World Cup group stage', '2023 Cricket World Cup qualification', '2027 Cricket World Cup', 'India at the Cricket World Cup', '2023 Cricket World Cup Qualifier Play-off']\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m 2023 Cricket World Cup is the answer.\n",
            "Action: Finish[2023 Cricket World Cup]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'What is CWC 2023?', 'output': '2023 Cricket World Cup'}"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docstore_agent(\"What is Cricket world cup 2023? and where it is held?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KofdsoLjIQL",
        "outputId": "9bb0b9b3-8138-483c-bd48-365394d567cf"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to search Cricket world cup 2023, find what it is and where it is held.\n",
            "Action: Search[Cricket world cup 2023]\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-9Qvrmgf4mTfjdG3hsylu25hT on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Observation: \u001b[36;1m\u001b[1;3mCould not find [Cricket world cup 2023]. Similar: ['2023 Cricket World Cup', 'Cricket World Cup', '2023 Cricket World Cup Qualifier', '2023 Cricket World Cup squads', '2023 Cricket World Cup statistics', '2023 Cricket World Cup group stage', '2023 Cricket World Cup Qualifier Play-off', 'India at the Cricket World Cup', '2023 Cricket World Cup officials', '2023 Cricket World Cup qualification']\u001b[0m\n",
            "Thought:"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-9Qvrmgf4mTfjdG3hsylu25hT on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-9Qvrmgf4mTfjdG3hsylu25hT on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m To find what it is and where it is held, I can search 2023 Cricket World Cup.\n",
            "Action: Search[2023 Cricket World Cup]\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-9Qvrmgf4mTfjdG3hsylu25hT on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Observation: \u001b[36;1m\u001b[1;3mCould not find [2023 Cricket World Cup]. Similar: ['2023 Cricket World Cup', '2023 Cricket World Cup Qualifier', 'Cricket World Cup', '2023 Cricket World Cup squads', '2023 Cricket World Cup statistics', '2023 Cricket World Cup group stage', '2023 Cricket World Cup qualification', '2027 Cricket World Cup', 'India at the Cricket World Cup', '2023 Cricket World Cup Qualifier Play-off']\u001b[0m\n",
            "Thought:"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-9Qvrmgf4mTfjdG3hsylu25hT on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-9Qvrmgf4mTfjdG3hsylu25hT on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.llms.base:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-9Qvrmgf4mTfjdG3hsylu25hT on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m To find what it is and where it is held, I can search 2023 Cricket World Cup.\n",
            "Action: Search[2023 Cricket World Cup]\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mCould not find [2023 Cricket World Cup]. Similar: ['2023 Cricket World Cup', '2023 Cricket World Cup Qualifier', 'Cricket World Cup', '2023 Cricket World Cup squads', '2023 Cricket World Cup statistics', '2023 Cricket World Cup group stage', '2023 Cricket World Cup qualification', '2027 Cricket World Cup', 'India at the Cricket World Cup', '2023 Cricket World Cup Qualifier Play-off']\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'What is Cricket world cup 2023? and where it is held?',\n",
              " 'output': 'Agent stopped due to iteration limit or time limit.'}"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agent Type : Self Ask with Search"
      ],
      "metadata": {
        "id": "qTBK9mNFl3AX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import OpenAI, SerpAPIWrapper\n",
        "from langchain.agents import initialize_agent, Tool\n",
        "\n",
        "search = SerpAPIWrapper(serpapi_api_key = 'api-key')\n",
        "tools = [\n",
        "    Tool(\n",
        "        name = \"Intermediate Answer\",\n",
        "        func = search.run,\n",
        "        description='google search'\n",
        "    )\n",
        "]\n",
        "\n",
        "self_ask_with_search = initialize_agent(tools, llm, agent='self-ask-with-search')"
      ],
      "metadata": {
        "id": "C8LTViKXl2pL"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(self_ask_with_search.agent.llm_chain.prompt.template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0m0zteojSwx",
        "outputId": "d255e3be-9fe9-4918-e44f-8d8edcc3593f"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Who lived longer, Muhammad Ali or Alan Turing?\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: How old was Muhammad Ali when he died?\n",
            "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
            "Follow up: How old was Alan Turing when he died?\n",
            "Intermediate answer: Alan Turing was 41 years old when he died.\n",
            "So the final answer is: Muhammad Ali\n",
            "\n",
            "Question: When was the founder of craigslist born?\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: Who was the founder of craigslist?\n",
            "Intermediate answer: Craigslist was founded by Craig Newmark.\n",
            "Follow up: When was Craig Newmark born?\n",
            "Intermediate answer: Craig Newmark was born on December 6, 1952.\n",
            "So the final answer is: December 6, 1952\n",
            "\n",
            "Question: Who was the maternal grandfather of George Washington?\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: Who was the mother of George Washington?\n",
            "Intermediate answer: The mother of George Washington was Mary Ball Washington.\n",
            "Follow up: Who was the father of Mary Ball Washington?\n",
            "Intermediate answer: The father of Mary Ball Washington was Joseph Ball.\n",
            "So the final answer is: Joseph Ball\n",
            "\n",
            "Question: Are both the directors of Jaws and Casino Royale from the same country?\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: Who is the director of Jaws?\n",
            "Intermediate answer: The director of Jaws is Steven Spielberg.\n",
            "Follow up: Where is Steven Spielberg from?\n",
            "Intermediate answer: The United States.\n",
            "Follow up: Who is the director of Casino Royale?\n",
            "Intermediate answer: The director of Casino Royale is Martin Campbell.\n",
            "Follow up: Where is Martin Campbell from?\n",
            "Intermediate answer: New Zealand.\n",
            "So the final answer is: No\n",
            "\n",
            "Question: {input}\n",
            "Are followup questions needed here:{agent_scratchpad}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hYPQ6XuYngZ_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}